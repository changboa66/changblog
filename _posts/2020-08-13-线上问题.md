---
layout: mypost
title: redis
categories: [java]
---
#### 如何应对高并发
```
1. 高性能的web服务器，数据库服务器。
2. 集群、分布式架构。
3. 优化sql。
4. 静态资源从nginx返回。
5. Nginx负载均衡。
6. CDN技术。
7. 缓存。
8. JVM优化。
9. 多线程。
10. 异步处理。
11. 数据库分库、分表、读写分离。
```
#### 定位线上CPU达到100%的问题
```
1. top找到最耗CPU的进程PID。
2. 显示进程PID下所有的线程PID。
3. 将线程PID转成十六进制。
4. jstack打印进程PID堆栈信息，根据线程PID过滤，即可看到是哪个方法出了问题。
5. 造成CPU过高的场景有死循环或者死锁。
```
#### 工作中遇到的最大困难
```
我说一个我们公司一直存在的一个问题吧，还有我是怎么解决的
  我们公司的服务部署特别繁琐，部署一次测试环境花费的时间也很长，超过了5分钟，因为是微服务架构，所以一次可能需要部署多个服务，
严重影响了效率。
  我在想解决方案的时候，就是想写一个java程序执行自动化部署流程，
当我写了点代码后又发现了问题，1. java先编译 后执行效率太低。2. 发送http请求不太友好。3. 即使写完了也只能后端同事用，前端同事没有java环境用不了。
  然后我想到了能不能用Shell脚本去写呢，但是我以前只用过linux命令 没有写过shell，我就尝试着去学了一下shell，
看了几天教程后，我就尝试着写了自动化部署脚本的第1版，中间遇到了一些语法的问题，经过努力都解决了，然后就顺利的把第一个服务部署到了测试环境，当时其实挺激动的，毕竟第一次用其他的语言写程序。然后又写了第2版，第3版，第4版。不断完善后，整个部署流程下来用了不到2分钟。
  其实写这个脚本没有花费我太多的时间，难度也谈不上大，但是我还是有了一些思考 为什么一直存在的问题大家都习以为常呢？
效率那么低为什么我们一直在忍？还有开发语言确实是相通的，即使有一些语法不一样，但是写代码的思想是一样的。
经过这件事后我还写了一篇总结，总结了一些自己的开发过程和对这件事的思考。
```
1. 为什么大家都对问题视而不见，习以为常
2. 学习新语言语法的困难
#### 自我介绍
```
面试官你好，我叫张常宝，2012年毕业于燕山大学里仁学院，学的是计算机科学与技术专业，到现在有8年的工作经验。
我的第一家公司是南天信息，主要从事银行类软件的开发。
第二家公司是和讯网，主要做了和讯通系统开发和维护。
第三家公司是宜信公司，做了虚拟账户和单点登陆系统。
最近的一家公司是易企秀，负责了轻松豆项目的开发和公共组件的开发。
用的技术有 Spring Boot, Dubbo, mysql, redis, maven, git, nginx等。
```
#### 敏捷开发scrum开发特点
```
0. 三个角色（产品负责人PO，推动者ScrumMaster，开发团队Team,人人平等）
1. 开发周期短，快速迭代（2~4周一上线）。
2. 需求评审会/估时估点会，拆解需求为故事点，每个故事点含有多个任务，评估每个小任务的工时。
3. 个人根据优先级主动领取任务，完成故事点后提测，继续领取任务。
4. 每日早会同步昨天任务进度及遇到的困难，和当天要需要完成的事项。
5. 上线后开复盘会。
```
#### 性能问题排查及解决方案
```
排查：
  1. 服务端压力太大，确实处理不过来。
  2. 使用了不恰当的同步锁。
  3. 调第三方资源不给力。
  4. 线程池配置的工作线程数不合理。
  5. 网络原因，丢包、重传、带宽限制。
  6.
1. 前端优化（减少Http请求数，CDN缓存，图片压缩）
3. 服务架构优化（分布式，缓存）
4. 数据库优化（索引，分库分表，读写分离）
5. 代码优化
5.1 for循环，新建大量对象，序列化反序列化，反射，正则表达式和数学计算消耗CPU，包装类与基础类拆箱操作，复杂和并行操作使用StreamAPI，根据业务场景创建线程池，根据业务场景选择并发容器，异步化，日志设置不合理
6. jvm优化
```
#### 自我学习能力
```
1. 设定目标
2. 拆解任务
3. 制定计划,实施计划,优化计划
4. 完成目标
5. 复盘总结
例子：
学习k8s
1. 先学习docker，再学习k8s，
2. 买了1本书《kubernetes权威指南》
3. 1周网上看完docker，4周学完k8s,基本概念和术语<Pod,Service,Deployment>
4. 总结学习要点
```
#### 架构师技能
```
1. 确认需求、拆分系统。(对整个系统纵向分解,对同一个逻辑层横向分解)
2. 技术选型。（依据整体架构进行技术选型）
3. 制作技术规格说明（与开发人员实时沟通，保证开发者依照原定架构实现各个功能）
4. 高质量代码。
5. 原理。
6.
```
#### 性能问题优化步骤
```
1. 目前现象。
2. 提出猜想（最难，jvm基础知识不够牢固）。
3. 验证猜想。
4. 定位问题（最难，使用工具）。
5. 解决问题。
```
#### 简历
```
熟悉GC常用算法，熟悉常见的垃圾收集器，具有实际jvm调优实战经验。
```
#### 秒杀场景
```
1. 行锁：for update 悲观锁。
2. version 乐观锁。
3. jvm内置锁synchronized加锁（单机）。
4. AQS
```
#### 限流
```
AQS信号量Semaphore限流
微服务从前往后tps逐级递减
```

背景：
晚上定时导入，运营同学也可以手动导入其他组的作品，近一段时间运营总反馈页面卡顿打不开的现象，一段时间后恢复(脚本自动重启了)。给运营带来了严重的困惑。
解决过程：
最初的解决方案是直接修改xms和xmx增大堆内存由1G变成2G，本以为就这么简单的解决了，没想到过了几天依然OOM，觉得很奇怪，就跟运营沟通说再次发现此问题时及时反馈，登陆服务器用jstat命令看到fullGC次数一直在增加。同时查看日志报了OOM，为了不影响运营操作无奈先重启了服务器。继续查看了启动参数用的是默认的PS和PO的垃圾回收器，查资料后又重启了服务加了PrintGCDateStamps、PrintGCDetail、DumpOnOutOfMemoryError参数打印gc日志和OOM时的堆栈信息，第二天OOM发生时依然先重启了服务，把gc日志和堆栈信息日志copy到本地，先看了gc日志发现跟jstat刚看到的一样，最后一直在fullGC，但始终无法回收内存。用本地的jvisualvm打开堆栈信息看对象数量，发现了是自己写的Redis分布式锁里ThreadLocal占用内存巨大，又是一顿查资料，学到了ThreadLocal用完必须手动remove(),否则就可能会造成内存泄漏，在unlock方法里手动remove()，上线，问题解决。
