---
layout: mypost
title: redis
categories: [redis]
---
#### 缓存的基本思想
```
避免用户在请求数据的时候速度过于缓慢，所以在数据库之上新增了缓存。
```
#### 缓存带来的问题
```
1. 系统复杂性增加。
2. 开发成本增加。
```
#### 本地缓存
```
1. HashMap、ConcurrentHashMap
2. Ehcache、Guava Cache、Sping Cache
缺点：数据无法共享。
```

#### Redis 的特点
```
1. 支持丰富的数据类型。
2. 支持数据持久化。
3. 有灾难恢复机制。
4. 支持集群模式。
5. 单线程IO多路复用模型。
6. 支持发布订阅、事务、lua脚本等功能。
```

#### Redis数据类型及常用命令
```
1. String(set, get, setex, setnx, strlen, incr)
2. List(lpush, lpop, rpush, rpop, lrange, llen)
3. Set(sadd, spop, smembers, sismembers, sunion)
4. Sorted-Set(zadd, zcard(获取总数), zrange)
5. Hash(hset, hget, hexists, hkeys, hvals)
```
#### 排行榜功能
```
zadd key score member
设置玩家分数：zadd 排行榜名称 分数 玩家标识
查看玩家分数：zscore 排行榜名称 玩家标识
查看排行榜：zrerange 排行榜名称 起始位置 结束位置 withscores
查看玩家名次：zrevrank 排行榜名称 玩家标识
增减玩家分数：zincrby 排行榜名称 分数增量/减量 玩家标识
从排行榜移除某玩家：zrem 排行榜名称 玩家标识
删除排行榜：del 排行榜名称
```
#### 选择Hash还是String类型存储数据？
```
1. 内存占用大小大致相同。
2. 如果filed很多，但每次需要操作少数filed，用Hash的hget、hset比较好。
3. 如果每次需要操作多个filed，用String的get、set比较好。
4. 官方推荐用Hash存储对象。
```
#### Redis 为什么快
```
1. 纯内存数据库。
2. 单线程保证每个操作的原子性，也减少了上下文切换和竞争。
3. 基于IO多路复用模型。
```

#### Redis内存满的淘汰策略
```
1. 从设置了过期时间的数据集中挑选快要过期的数据淘汰。
2. 从设置了过期时间的数据集中选择最近最少使用的数据淘汰。
3. 从设置了过期时间的数据集中随机淘汰。
4. 从所有的数据集中选择最近最少使用的数据淘汰。
5. 从所有的数据集中随机淘汰。
6. 禁止写入数据。
```
#### Redis持久化机制
```
1. 快照 RDB，高效，丢失数据。
2. 追加文件 AOF，
2.1 appendfsync=always:每次数据变更都写入磁盘，性能差。
2.2 appendfsync=everysec:每分钟写入磁盘一次。
2.3 appendfsync=no：从不同步
```

#### Redis 事务
```
隔离性（有），原子性（无），一致性（无），持久性（AOF模式下，设置appendfsync=always写入才有）
1. mutil（开启事务）
2. set book "alibaba"   # 返回 QUEUED
3. sadd tags "programming"   # 返回 QUEUED
4. exec（执行事务，不具有原子性，中间某条命令失败不会影响其他命令的执行结果）
4.1 discard（放弃事务）
-------------------
watch mykey （乐观锁）
var = get mykey
var = var + 1
mutil
set mykey $var
exec
如果在watch ~ exec这段时间有其他线程修改了mykey的值，则此事务执行失败。
```

#### 缓存穿透
```
查询一个不存在的数据，由于缓存不命中时需要到数据库查询，查询不到数据不写入缓存，这将导致每次请求查询这个不存在的数据都要到数据库查询，造成缓存穿透。
解决方案：1. 如果查询结果为空，我们就把这个空结果缓存，时间短一些。
2. 布隆过滤器。
```
#### 缓存击穿
```
是指一个key非常热点，在不停的扛着大并发，大并发集中对这一个点进行访问，当这个key在失效的瞬间，持续的大并发就穿破缓存，直接请求数据库，瞬间对数据库的访问压力增大。
解决方案：1. 查询缓存为空时加锁，从数据库查询到数据加载到缓存后再释放锁。
```
#### 缓存雪崩
```
缓存在同一时间大面积失效, 造成数据库短时间内承受大量的请求。
解决方案：1. 采用redis集群，避免单机出现问题这个缓存服务都不可用。
2. 限流。
3. 设置不同的key不同的失效时间。
4. 设置永不过期。
```
#### 布隆过滤器
```
由一个很长的位数组和一组hash函数组成。
1. 设值阶段：入库一条id=99的数据，入库后用每个hash函数对99求hash值，然后用求到的hash值与位数组的长度取模来确定在位数组的下标，将这些下标对应的值修改为1。
2. 查询阶段：查询id=99的数据，用同样的一组hash函数对99求hash值，用hash值与位数组长度取模求到下标，如果每个hash函数求到的下标映射的值都是1，那么这条数据存在于数据库中，允许访问数据库，如果有的映射到0，则此id肯定不存在于数据库中，直接返回。
```
#### 布隆过滤器的作用
```
1. 判断大数据里某个值是否存在。
2. 解决缓存穿透。
3. 爬虫、邮箱等系统的过滤。
```

#### 缓存和数据库一致性
```
1. 强一致性：任意时刻所有节点的数据都是一致的。
2. 最终一致性：不保证任意时刻任意节点的数据都是相同的，但是随着时间的迁移，不同节点上的同一份数据总是在向趋同的方向变化。也可以简单的理解为在一段时间后，节点间的数据最终会达到一致性。（例子：DNS）
3. 缓存必须要有过期时间。
4. 保证数据库跟缓存最终一致性即可，不追求强一致性。
5. 我们在交易创建流程中，首先创建一个订单，然后在同步调用扣减优惠券和扣减库存时，针对调用异常（失败或者超时），发出废单消息到MQ。如果消息发送失败，本地会做时间阶梯式的异步重试；优惠券系统和库存系统收到消息后，会进行判断是否需要做业务回滚，这样就准实时地保证了多个本地事务的最终一致性。
```
#### 如何保证缓存和数据库一致性
```
从理论上来说，给缓存设置过期时间是保证最终一致性的解决方案。对所有写操作以数据库为准，对缓存操作只是尽最大努力即可。也就是说如果写数据库成功，缓存更新失败，只要到达过期时间,后面的读请求自然会读取新值回填缓存。
更新缓存
   优点：不会有缓存不命中的情况。
   缺点：只是将这个值修改为新值时更新和淘汰消耗差不多；但是业务逻辑复杂(一系列复杂的计算等)时，更新缓存操作的消耗大于淘汰缓存。
淘汰缓存：
   优点：操作简单。
   缺点：淘汰缓存后，下一次查询缓存不命中，需要读取数据库一次。
方案一：先更新缓存，再更新数据库。
   1. 请求A更新了缓存
   2. 请求B更新了缓存
   3. 请求B更新了数据库
   4. 请求A更新了数据库
方案二：先更新了数据库，再更新缓存。
   1. 请求A更新了数据库
   2. 请求B更新了数据库
   3. 请求B更新了缓存
   4. 请求A更新了缓存
解决思路是"串行化"，可以对数据加分布式锁,更新缓存操作可能会大大消耗性能，因此直接考虑淘汰缓存更合适。
方案三：先删除缓存，再更新数据库。
   1. 请求A删除缓存。
   2. 请求B查询发现缓存不存在。
   3. 请求B去查询数据库得到旧值。
   4. 请求B将旧值写入缓存。
   5. 请求A将新值写入数据库。
解决思路是采用延时双删，经过5步后请求A再起一个线程异步休眠1秒后删除一次缓存。
方案四：先更新数据库，再删除缓存（最好的方案）。
   1. 缓存刚好失效。
   2. 请求A从数据库取到一个旧值。
   3. 请求B更新数据库。
   4. 请求B删除空缓存。
   5. 请求A将旧值写入缓存。
解决思路是采用延时双删，经过5步后请求B再起一个线程异步休眠1秒后删除一次缓存。
方案五：把Redis当做想象成mysql的从库，读取binlog后分析，利用消息队列，推送更新redis缓存。(阿里巴巴canal开源框架)

```
#### Redis集群方案
```
1. 主从复制模式
2. Sentinel哨兵模式（基于主从复制模式，只是引入哨兵来监控与自动处理故障）
3. Redis-Cluster(服务端sharding,16384个槽,每个节点负责一部分槽,key经过CRC16后16384取模找到对应的槽)
4. Redis-Sharding(客户端sharding,一致性hash算法,将key进行散列，特定的key映射到特定的节点上)
```

#### 一致性hash算法
```
1. 首先求出节点(Redis、Memcached)的哈希值，并将其分配到0~2^32-1的圆上。
2. 然后采用同样的方法求出存储数据键的哈希值，并映射到这个圆上。
3. 然后从键映射到的位置顺时针查找，将数据保存在找到的第一个节点上，如果超过了2^32-1仍然找不到节点就将数据保存到第一台节点上。
```
#### redis实现排序
```
0. 不用list是因为LPOP删除表头，RPOP删除表尾，没有删除指定元素的命令
1. zset
   zadd key score member
   主题下的评论按创建时间排序
   1. zadd topicId create_time commentId
   评论详情用hash存储
   hset commitId field1 "value1" field2 "value2"
   设置key的过期时长
   EXPIRE key seconds
   2. 按创建时间倒序取10条数据
   zrerange topicId 0 10 withscores
   3. 删除某条评论
   zrem topicId commitId
```
